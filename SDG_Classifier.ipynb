{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# standard library\nfrom typing import List\nfrom textwrap import wrap\n\n#data wrangling\nimport pandas as pd\nimport numpy as np\n\n# nlp\nimport spacy\n\n# data modelling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n# utils\nfrom tqdm import tqdm\n\n# visualisations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# saving the model.\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:39:42.241486Z","iopub.execute_input":"2021-12-02T15:39:42.241863Z","iopub.status.idle":"2021-12-02T15:39:53.384408Z","shell.execute_reply.started":"2021-12-02T15:39:42.241776Z","shell.execute_reply":"2021-12-02T15:39:53.383331Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('https://zenodo.org/record/5550238/files/osdg-community-dataset-v21-09-30.csv?download=1')\nprint('Shape:', df.shape)\ndisplay(df.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:39:53.386518Z","iopub.execute_input":"2021-12-02T15:39:53.386843Z","iopub.status.idle":"2021-12-02T15:40:07.216137Z","shell.execute_reply.started":"2021-12-02T15:39:53.386802Z","shell.execute_reply":"2021-12-02T15:40:07.215155Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.loc[df.sdg == 15].sample(5)[['text', 'sdg']]         ","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:07.217423Z","iopub.execute_input":"2021-12-02T15:40:07.217662Z","iopub.status.idle":"2021-12-02T15:40:07.239289Z","shell.execute_reply.started":"2021-12-02T15:40:07.217632Z","shell.execute_reply":"2021-12-02T15:40:07.238380Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#unique classes in sdg                               \nsorted(df[\"sdg\"].unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:07.241696Z","iopub.execute_input":"2021-12-02T15:40:07.242094Z","iopub.status.idle":"2021-12-02T15:40:07.250572Z","shell.execute_reply.started":"2021-12-02T15:40:07.242046Z","shell.execute_reply":"2021-12-02T15:40:07.249976Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df[\"sdg\"] = df[\"sdg\"] -1                          ","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:07.251705Z","iopub.execute_input":"2021-12-02T15:40:07.251930Z","iopub.status.idle":"2021-12-02T15:40:07.263087Z","shell.execute_reply.started":"2021-12-02T15:40:07.251903Z","shell.execute_reply":"2021-12-02T15:40:07.262042Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Get the lists of sentences and their labels.\nsentences = df.text.values                                    \nlabels = df.sdg.values","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:07.265263Z","iopub.execute_input":"2021-12-02T15:40:07.265471Z","iopub.status.idle":"2021-12-02T15:40:07.274994Z","shell.execute_reply.started":"2021-12-02T15:40:07.265445Z","shell.execute_reply":"2021-12-02T15:40:07.274178Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# calculating cumulative probability over agreement scores                                               \n\ndf_lambda = df['agreement'].value_counts(normalize = True).sort_index().cumsum().to_frame(name = 'p_sum')             \ndf_lambda.reset_index(inplace = True)\ndf_lambda.rename({'index': 'agreement'}, axis = 1, inplace = True)\n\nprint('Shape:', df_lambda.shape)\ndisplay(df_lambda.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:07.275984Z","iopub.execute_input":"2021-12-02T15:40:07.276219Z","iopub.status.idle":"2021-12-02T15:40:07.302615Z","shell.execute_reply.started":"2021-12-02T15:40:07.276192Z","shell.execute_reply":"2021-12-02T15:40:07.302009Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.io as pio\n\nfig = px.line(\n    data_frame = df_lambda,                                                                    \n    x = 'agreement',\n    y = 'p_sum',\n    markers = True,\n    labels = {\n        'agreement': 'Agreement Score',\n        'p_sum': 'Cumulative Probrability'\n    },\n    color_discrete_sequence = ['#1f77b4'],\n    title = 'Figure 1. Cumulative Distribution Function of the Agreement Score'\n)\n\nfig.update_traces(hovertemplate = 'Agreement score: %{x:.2f}<br>Cumulative probability: %{y:.2f}')\nfig.update_layout(\n    xaxis = {'dtick': 0.1},\n    yaxis = {'dtick': 0.25}\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:07.303827Z","iopub.execute_input":"2021-12-02T15:40:07.304363Z","iopub.status.idle":"2021-12-02T15:40:09.611892Z","shell.execute_reply.started":"2021-12-02T15:40:07.304327Z","shell.execute_reply":"2021-12-02T15:40:09.610978Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# keeping only the texts whose suggested sdg labels is accepted and the agreement score is at least .6\n\nprint('Shape before:', df.shape)\ndf_osdg = df.query('agreement >= .6 and labels_positive > labels_negative').copy()                       \nprint('Shape after :', df_osdg.shape)\ndisplay(df_osdg.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.613311Z","iopub.execute_input":"2021-12-02T15:40:09.613611Z","iopub.status.idle":"2021-12-02T15:40:09.641339Z","shell.execute_reply.started":"2021-12-02T15:40:09.613570Z","shell.execute_reply":"2021-12-02T15:40:09.640758Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_lambda = df_osdg.groupby('sdg', as_index = False).agg(count = ('text_id', 'count'))\ndf_lambda['share'] = df_lambda['count'].divide(df_lambda['count'].sum()).multiply(100)                         \nprint('Shape:', df_lambda.shape)\ndisplay(df_lambda)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.643662Z","iopub.execute_input":"2021-12-02T15:40:09.644321Z","iopub.status.idle":"2021-12-02T15:40:09.673293Z","shell.execute_reply.started":"2021-12-02T15:40:09.644290Z","shell.execute_reply":"2021-12-02T15:40:09.672470Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(\n    data_frame = df_lambda,\n    x = 'sdg',\n    y = 'count',\n    custom_data = ['share'],\n    labels = {\n        'sdg': 'SDG',\n        'count': 'Count'                                                                                                 \n    },\n    color_discrete_sequence = ['#1f77b4'],\n    title = 'Figure 2. Distribution of Texts (Agreement >.6) over SDGs'\n)\n\nfig.update_traces(hovertemplate = 'SDG %{x}<br>Count: %{y}<br>Share: %{customdata:.2f}%')\nfig.update_layout(xaxis = {'type': 'category'})\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.674691Z","iopub.execute_input":"2021-12-02T15:40:09.674927Z","iopub.status.idle":"2021-12-02T15:40:09.763022Z","shell.execute_reply.started":"2021-12-02T15:40:09.674896Z","shell.execute_reply":"2021-12-02T15:40:09.762180Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_true: np.ndarray, y_hat: np.ndarray, figsize = (16, 9)):\n    \"\"\"\n    Convenience function to display a confusion matrix in a graph.\n    \"\"\"\n    labels = sorted(list(set(y_true)))\n    df_lambda = pd.DataFrame(\n        confusion_matrix(y_true, y_hat),\n        index = labels,\n        columns = labels\n    )\n    acc = accuracy_score(y_true, y_hat)\n    f1s = f1_score(y_true, y_hat, average = 'weighted')\n\n    fig, ax = plt.subplots(figsize = figsize)\n    sns.heatmap(                                                                                                 \n        df_lambda, annot = True, square = True, cbar = False,\n        fmt = 'd', linewidths = .5, cmap = 'YlGnBu',\n        ax = ax\n    )\n    ax.set(\n        title = f'Accuracy: {acc:.2f}, F1 (weighted): {f1s:.2f}',\n        xlabel = 'Predicted',\n        ylabel = 'Actual'\n    )\n    fig.suptitle('Confusion Matrix')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.764608Z","iopub.execute_input":"2021-12-02T15:40:09.765091Z","iopub.status.idle":"2021-12-02T15:40:09.774678Z","shell.execute_reply.started":"2021-12-02T15:40:09.765041Z","shell.execute_reply":"2021-12-02T15:40:09.774031Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_top_features(vectoriser, clf, selector = None, top_n: int = 25, how: str = 'long'):\n    \"\"\"\n    Convenience function to extract top_n predictor per class from a model.\n    \"\"\"\n\n    assert hasattr(vectoriser, 'get_feature_names')\n    assert hasattr(clf, 'coef_')\n    assert hasattr(selector, 'get_support')\n    assert how in {'long', 'wide'}, f'how must be either long or wide not {how}'\n\n    features = vectoriser.get_feature_names_out()\n    if selector is not None:\n        features = features[selector.get_support()]\n    axis_names = [f'freature_{x + 1}' for x in range(top_n)]\n\n    if len(clf.classes_) > 2:\n        results = list()\n        for c, coefs in zip(clf.classes_, clf.coef_):\n            idx = coefs.argsort()[::-1][:top_n]\n            results.extend(tuple(zip([c] * top_n, features[idx], coefs[idx])))\n    else:\n        coefs = clf.coef_.flatten()\n        idx = coefs.argsort()[::-1][:top_n]\n        results = tuple(zip([clf.classes_[1]] * top_n, features[idx], coefs[idx]))\n\n    df_lambda = pd.DataFrame(results, columns =  ['sdg', 'feature', 'coef'])\n\n    if how == 'wide':\n        df_lambda = pd.DataFrame(\n            np.array_split(df_lambda['feature'].values, len(df_lambda) / top_n),\n            index = clf.classes_ if len(clf.classes_) > 2 else [clf.classes_[1]],\n            columns = axis_names\n        )\n\n    return df_lambda","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.776081Z","iopub.execute_input":"2021-12-02T15:40:09.776609Z","iopub.status.idle":"2021-12-02T15:40:09.791727Z","shell.execute_reply.started":"2021-12-02T15:40:09.776564Z","shell.execute_reply":"2021-12-02T15:40:09.791028Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def fix_sdg_name(sdg: str, width: int = 30) -> str:\n    sdg_id2name = {\n        1: 'GOAL 1: No Poverty',\n        2: 'GOAL 2: Zero Hunger',\n        3: 'GOAL 3: Good Health and Well-being',\n        4: 'GOAL 4: Quality Education',\n        5: 'GOAL 5: Gender Equality',\n        6: 'GOAL 6: Clean Water and Sanitation',\n        7: 'GOAL 7: Affordable and Clean Energy',\n        8: 'GOAL 8: Decent Work and Economic Growth',\n        9: 'GOAL 9: Industry, Innovation and Infrastructure',\n        10: 'GOAL 10: Reduced Inequality',\n        11: 'GOAL 11: Sustainable Cities and Communities',\n        12: 'GOAL 12: Responsible Consumption and Production',\n        13: 'GOAL 13: Climate Action',\n        14: 'GOAL 14: Life Below Water',\n        15: 'GOAL 15: Life on Land',\n        16: 'GOAL 16: Peace and Justice Strong Institutions',\n        17: 'GOAL 17: Partnerships to achieve the Goal'\n    }\n\n    name = sdg_id2name[int(sdg)]\n    return '<br>'.join(wrap(name, 30))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.793048Z","iopub.execute_input":"2021-12-02T15:40:09.793436Z","iopub.status.idle":"2021-12-02T15:40:09.807286Z","shell.execute_reply.started":"2021-12-02T15:40:09.793405Z","shell.execute_reply":"2021-12-02T15:40:09.806464Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# other settings\npio.templates.default = 'plotly_white'\n\nspacy.prefer_gpu()                                                                                             \nnlp = spacy.load('en_core_web_sm', disable = ['ner'])\nprint('Disabled spaCy components:', nlp.disabled)\nprint('SpaCy version:', spacy.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:09.808485Z","iopub.execute_input":"2021-12-02T15:40:09.808833Z","iopub.status.idle":"2021-12-02T15:40:10.688438Z","shell.execute_reply.started":"2021-12-02T15:40:09.808804Z","shell.execute_reply":"2021-12-02T15:40:10.687600Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def preprocess_spacy(alpha: List[str]) -> List[str]:\n    \"\"\"\n    Preprocess text input using spaCy.\n    \n    Parameters\n    ----------\n    alpha: List[str]\n        a text corpus.\n    \n    Returns\n    -------\n    doc: List[str]\n        a cleaned version of the original text corpus.\n    \"\"\"\n    docs = list()\n    \n    for doc in tqdm(nlp.pipe(alpha, batch_size = 128)):\n        tokens = list()\n        for token in doc:                                                                                    \n            if token.pos_ in ['NOUN', 'VERB', 'ADJ']:\n                tokens.append(token.lemma_)\n        docs.append(' '.join(tokens))\n        \n    return docs","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:10.689871Z","iopub.execute_input":"2021-12-02T15:40:10.690279Z","iopub.status.idle":"2021-12-02T15:40:10.698183Z","shell.execute_reply.started":"2021-12-02T15:40:10.690233Z","shell.execute_reply":"2021-12-02T15:40:10.697256Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_osdg['docs'] = preprocess_spacy(df_osdg['text'].values)                                               \nprint('Shape:', df_osdg.shape)\ndisplay(df_osdg.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:40:10.699824Z","iopub.execute_input":"2021-12-02T15:40:10.700318Z","iopub.status.idle":"2021-12-02T15:42:45.187893Z","shell.execute_reply.started":"2021-12-02T15:40:10.700272Z","shell.execute_reply":"2021-12-02T15:42:45.187014Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    df_osdg['docs'].values,                                                                                       \n    df_osdg['sdg'].values, \n    test_size = .3,\n    random_state = 50\n)\n\nprint('Shape train:', X_train.shape)\nprint('Shape test:', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:42:45.189405Z","iopub.execute_input":"2021-12-02T15:42:45.189667Z","iopub.status.idle":"2021-12-02T15:42:45.199039Z","shell.execute_reply.started":"2021-12-02T15:42:45.189636Z","shell.execute_reply":"2021-12-02T15:42:45.198135Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\npipe1 = Pipeline([\n    ('vectoriser', TfidfVectorizer(\n        ngram_range = (1, 2),\n        max_df = 0.75,\n        min_df = 2,\n        max_features = 100_000\n    )),\n    ('selector', SelectKBest(f_classif, k = 5_000)),                                                     \n    ('clf', MultinomialNB()\n    )\n])\n\npipe1.fit(X_train, y_train)\n\ny_hat1 = pipe1.predict(X_test)\nplot_confusion_matrix(y_test, y_hat1)\n\nprint(classification_report(y_test, y_hat1, zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:42:45.200318Z","iopub.execute_input":"2021-12-02T15:42:45.200549Z","iopub.status.idle":"2021-12-02T15:42:50.276521Z","shell.execute_reply.started":"2021-12-02T15:42:45.200521Z","shell.execute_reply":"2021-12-02T15:42:50.275962Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\npipe2 = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('selector', SelectKBest(f_classif, k = 5_000)),\n    ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))           \n    \n])\n\npipe2.fit(X_train, y_train)\n\ny_hat2 = pipe2.predict(X_test)\nplot_confusion_matrix(y_test, y_hat2)\n\nprint(classification_report(y_test, y_hat2, zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:42:50.277734Z","iopub.execute_input":"2021-12-02T15:42:50.278157Z","iopub.status.idle":"2021-12-02T15:42:53.048897Z","shell.execute_reply.started":"2021-12-02T15:42:50.278105Z","shell.execute_reply":"2021-12-02T15:42:53.047743Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\npipe3 = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('selector', SelectKBest(f_classif, k = 5_000)),                                                         \n    ('clf', MultinomialNB())\n    \n])\n\npipe3.fit(X_train, y_train)\n\ny_hat3 = pipe3.predict(X_test)\nplot_confusion_matrix(y_test, y_hat3)\n\nprint(classification_report(y_test, y_hat3, zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:42:53.050661Z","iopub.execute_input":"2021-12-02T15:42:53.051090Z","iopub.status.idle":"2021-12-02T15:42:55.651801Z","shell.execute_reply.started":"2021-12-02T15:42:53.051045Z","shell.execute_reply":"2021-12-02T15:42:55.650932Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"pipe4 = Pipeline([\n    ('vectoriser', TfidfVectorizer(\n        ngram_range = (1, 2),\n        max_df = 0.75,\n        min_df = 2,\n        max_features = 100_000\n    )),\n    ('selector', SelectKBest(f_classif, k = 5_000)),                                                               \n    ('clf', LogisticRegression(\n        penalty = 'l2',\n        C = .9,\n        multi_class = 'multinomial',\n        class_weight = 'balanced',\n        random_state = 42,\n        solver = 'newton-cg',\n        max_iter = 100\n    ))\n])\n\npipe4.fit(X_train, y_train)\n\ny_hat4 = pipe4.predict(X_test)\nplot_confusion_matrix(y_test, y_hat4)\n\nprint(classification_report(y_test, y_hat4, zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:42:55.653031Z","iopub.execute_input":"2021-12-02T15:42:55.653244Z","iopub.status.idle":"2021-12-02T15:43:03.342616Z","shell.execute_reply.started":"2021-12-02T15:42:55.653218Z","shell.execute_reply":"2021-12-02T15:43:03.341708Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"with open('pipe4_pickle','wb') as f:\n    pickle.dump(pipe4,f)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:43:03.344184Z","iopub.execute_input":"2021-12-02T15:43:03.344705Z","iopub.status.idle":"2021-12-02T15:43:03.861704Z","shell.execute_reply.started":"2021-12-02T15:43:03.344672Z","shell.execute_reply":"2021-12-02T15:43:03.860769Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"with open('pipe4_pickle','rb') as f:\n    mp = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:43:03.862901Z","iopub.execute_input":"2021-12-02T15:43:03.863167Z","iopub.status.idle":"2021-12-02T15:43:04.047450Z","shell.execute_reply.started":"2021-12-02T15:43:03.863135Z","shell.execute_reply":"2021-12-02T15:43:04.046284Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"y_hat5 = mp.predict(X_test)\nprint(classification_report(y_test, y_hat5, zero_division = 0))  # model \"pipe4\" saved as f and called as an object \"mp\" and that givers same result as y_hat5","metadata":{"execution":{"iopub.status.busy":"2021-12-02T15:43:04.048778Z","iopub.execute_input":"2021-12-02T15:43:04.049043Z","iopub.status.idle":"2021-12-02T15:43:04.788299Z","shell.execute_reply.started":"2021-12-02T15:43:04.049008Z","shell.execute_reply":"2021-12-02T15:43:04.787431Z"},"trusted":true},"execution_count":25,"outputs":[]}]}